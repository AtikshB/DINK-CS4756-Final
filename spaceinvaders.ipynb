{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import AtariDataset\n",
    "import gym\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display as ipythondisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEEDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reseed(seed):\n",
    "  torch.manual_seed(seed)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "seed = 42\n",
    "reseed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[1960, 1870, 1770, 1705, 1700]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m AtariDataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124matari_v1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m observations, actions \u001b[38;5;241m=\u001b[39m dataloader\u001b[38;5;241m.\u001b[39mcompile_data()\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "dataloader = AtariDataset(\"atari_v1\")\n",
    "observations, actions, rewards, next_observations, dones = dataloader.compile_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAKE ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "(210, 160)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "def make_env(env_id, seed=25):\n",
    "    env = gym.make(env_id, obs_type='grayscale', render_mode=None, repeat_action_probability=0.15,frameskip=1)\n",
    "    env.seed(seed)\n",
    "    env.action_space.seed(seed)\n",
    "    env.observation_space.seed(seed)\n",
    "    return env\n",
    "env = make_env(\"SpaceInvaders-v0\", seed=seed)\n",
    "print(env.action_space.n)\n",
    "print(env.observation_space.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN DQN (TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dqn import DQN\n",
    "import dqn\n",
    "\n",
    "INPUT_SHAPE = (210, 160)\n",
    "ACTION_SIZE = env.action_space.n\n",
    "\n",
    "dqn_learner = DQN(INPUT_SHAPE, ACTION_SIZE)\n",
    "\n",
    "dqn.train(dqn_learner, env, observations=observations, actions=actions, rewards=rewards, next_observations=next_observations, dones=dones, save_path='models/dqn_test.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the learner\n",
      "Training for 40 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 1/40 [00:19<12:49, 19.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2328628909548205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:39<12:27, 19.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.09765370158450021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/40 [00:57<11:36, 18.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.08236520489168753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 4/40 [01:14<11:01, 18.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.07443511830046087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 5/40 [01:31<10:23, 17.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.0692666074950839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 6/40 [01:48<09:50, 17.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.06509735768685687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 7/40 [02:04<09:24, 17.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.06211118761202208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 8/40 [02:21<08:58, 16.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.059370186522892825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 9/40 [02:37<08:40, 16.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.056966968130095344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 10/40 [02:55<08:30, 17.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.05515189998744088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 11/40 [03:12<08:13, 17.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.05301044978300527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 12/40 [03:30<08:10, 17.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.05154143571335071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 13/40 [03:49<07:59, 17.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.050305204287308634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 14/40 [04:06<07:36, 17.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.048640288734539745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 15/40 [04:23<07:13, 17.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.047475668442041874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 16/40 [04:39<06:50, 17.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 0.04637358335841032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 17/40 [04:56<06:29, 16.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 0.04509320502866254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 18/40 [05:12<06:08, 16.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 0.044029522883946966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 19/40 [05:29<05:49, 16.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 0.04287427127895116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 20/40 [05:45<05:31, 16.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.04217651392170204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 21/40 [06:01<05:14, 16.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.04118504779411436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 22/40 [06:18<04:57, 16.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Loss: 0.04024586619456568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 23/40 [06:34<04:40, 16.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Loss: 0.03981901526374851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 24/40 [06:51<04:24, 16.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Loss: 0.038817869599454845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 25/40 [07:08<04:10, 16.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Loss: 0.0381938560814916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 26/40 [07:25<03:56, 16.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Loss: 0.037224467491755835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 27/40 [07:42<03:39, 16.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Loss: 0.03671300086403454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 28/40 [07:59<03:23, 16.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Loss: 0.03613608223755015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 29/40 [08:17<03:07, 17.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Loss: 0.03564826463161374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 30/40 [08:34<02:51, 17.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Loss: 0.03460118074141664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 31/40 [08:51<02:34, 17.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 0.03443758685694685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 32/40 [09:08<02:16, 17.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Loss: 0.03386444329452856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 33/40 [09:26<02:01, 17.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Loss: 0.03322192889198798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 34/40 [09:43<01:44, 17.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Loss: 0.03271194785238533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 35/40 [10:01<01:26, 17.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Loss: 0.03248046584419731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 36/40 [10:18<01:09, 17.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Loss: 0.03174151636866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 37/40 [10:35<00:51, 17.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Loss: 0.03136699610121907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 38/40 [10:53<00:34, 17.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Loss: 0.030783186944443715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 39/40 [11:10<00:17, 17.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Loss: 0.030496925144869083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [11:27<00:00, 17.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Loss: 0.029993618590682898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpaceInvLearner(\n",
       "  (fc1): Linear(in_features=33600, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc_out): Linear(in_features=256, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bc import SpaceInvLearner\n",
    "import bc\n",
    "\n",
    "learner = SpaceInvLearner(env)\n",
    "\n",
    "bc.train(learner=learner, observations=observations, checkpoint_path=\"models/bc_learner.pth\", actions=actions, num_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127.25\n"
     ]
    }
   ],
   "source": [
    "learner.load_state_dict(torch.load(\"models/bc_learner.pth\"), strict=True)\n",
    "total_learner_reward = 0\n",
    "done = False\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for i in range(20):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        with torch.no_grad():\n",
    "            action = learner.get_action(torch.Tensor([obs]).to(device))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_learner_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "print(total_learner_reward/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD EXPERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from expert.ppo import PPOAgent, ActorCnn, CriticCnn\n",
    "\n",
    "INPUT_SHAPE = (4, 84, 84)\n",
    "ACTION_SIZE = env.action_space.n\n",
    "SEED = 0\n",
    "GAMMA = 0.99           # discount factor\n",
    "ALPHA= 0.0001          # Actor learning rate\n",
    "BETA = 0.0001          # Critic learning rate\n",
    "TAU = 0.95\n",
    "BATCH_SIZE = 32\n",
    "PPO_EPOCH = 5\n",
    "CLIP_PARAM = 0.2\n",
    "UPDATE_EVERY = 1000     # how often to update the network \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "agent = PPOAgent(INPUT_SHAPE, ACTION_SIZE, SEED, device, GAMMA, ALPHA, BETA, TAU, UPDATE_EVERY, BATCH_SIZE, PPO_EPOCH, CLIP_PARAM, ActorCnn(INPUT_SHAPE, ACTION_SIZE), CriticCnn(INPUT_SHAPE))\n",
    "agent.load_model(\"models/expert_actor.pth\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAgger Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After interaction 0, reward = 50.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.2291255757028674\n",
      "Epoch 1, Loss: 0.17323820734465564\n",
      "Epoch 2, Loss: 0.1555330808515902\n",
      "Epoch 3, Loss: 0.14674009106777333\n",
      "Epoch 4, Loss: 0.14217397589006542\n",
      "Epoch 5, Loss: 0.13803996384879688\n",
      "Epoch 6, Loss: 0.1353701772513213\n",
      "Epoch 7, Loss: 0.1326952221584909\n",
      "Epoch 8, Loss: 0.1309829733253997\n",
      "Epoch 9, Loss: 0.12841376533478865\n",
      "Epoch 10, Loss: 0.1281951579414768\n",
      "Epoch 11, Loss: 0.12567432427111966\n",
      "Epoch 12, Loss: 0.12410514976507352\n",
      "Epoch 13, Loss: 0.12316190092651932\n",
      "Epoch 14, Loss: 0.1219550437397427\n",
      "Epoch 15, Loss: 0.12118014113770591\n",
      "Epoch 16, Loss: 0.1200339741728924\n",
      "Epoch 17, Loss: 0.11922966596888906\n",
      "Epoch 18, Loss: 0.11753706652441143\n",
      "Epoch 19, Loss: 0.11707328039186972\n",
      "After interaction 1, reward = 135.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.1677919045420297\n",
      "Epoch 1, Loss: 0.1543796840376021\n",
      "Epoch 2, Loss: 0.1446054458709094\n",
      "Epoch 3, Loss: 0.14156718197485402\n",
      "Epoch 4, Loss: 0.136964693733702\n",
      "Epoch 5, Loss: 0.13613329983503195\n",
      "Epoch 6, Loss: 0.13387353065857716\n",
      "Epoch 7, Loss: 0.13325786281414018\n",
      "Epoch 8, Loss: 0.1306022534517729\n",
      "Epoch 9, Loss: 0.1318537153468434\n",
      "Epoch 10, Loss: 0.1293386684788901\n",
      "Epoch 11, Loss: 0.12919349843404568\n",
      "Epoch 12, Loss: 0.12734324402658198\n",
      "Epoch 13, Loss: 0.12786437042517848\n",
      "Epoch 14, Loss: 0.1253919999941354\n",
      "Epoch 15, Loss: 0.12501259701657533\n",
      "Epoch 16, Loss: 0.12275229030715701\n",
      "Epoch 17, Loss: 0.12313022226959035\n",
      "Epoch 18, Loss: 0.12480017396214352\n",
      "Epoch 19, Loss: 0.12425769215363024\n",
      "After interaction 2, reward = 60.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.15480801605325095\n",
      "Epoch 1, Loss: 0.13947848966771045\n",
      "Epoch 2, Loss: 0.13403799424825558\n",
      "Epoch 3, Loss: 0.13081064615880045\n",
      "Epoch 4, Loss: 0.1281566830207529\n",
      "Epoch 5, Loss: 0.12590815035059721\n",
      "Epoch 6, Loss: 0.12400860986700114\n",
      "Epoch 7, Loss: 0.12351971386263431\n",
      "Epoch 8, Loss: 0.1227455029401106\n",
      "Epoch 9, Loss: 0.12164999612757037\n",
      "Epoch 10, Loss: 0.12083365926685674\n",
      "Epoch 11, Loss: 0.12006057430036499\n",
      "Epoch 12, Loss: 0.11838556454326239\n",
      "Epoch 13, Loss: 0.11837950676205618\n",
      "Epoch 14, Loss: 0.11778050090813968\n",
      "Epoch 15, Loss: 0.1163153539358029\n",
      "Epoch 16, Loss: 0.11572902448193928\n",
      "Epoch 17, Loss: 0.11552855225787248\n",
      "Epoch 18, Loss: 0.11525893021767467\n",
      "Epoch 19, Loss: 0.11446249240613125\n",
      "After interaction 3, reward = 180.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.14382461786775266\n",
      "Epoch 1, Loss: 0.13647600086563724\n",
      "Epoch 2, Loss: 0.1334808005788232\n",
      "Epoch 3, Loss: 0.12918031375623693\n",
      "Epoch 4, Loss: 0.1297719698336165\n",
      "Epoch 5, Loss: 0.12871400978268877\n",
      "Epoch 6, Loss: 0.12675392013148398\n",
      "Epoch 7, Loss: 0.12578340535615123\n",
      "Epoch 8, Loss: 0.1247190186953814\n",
      "Epoch 9, Loss: 0.12494298470559093\n",
      "Epoch 10, Loss: 0.1247661322523645\n",
      "Epoch 11, Loss: 0.12327381244487008\n",
      "Epoch 12, Loss: 0.12448020460410307\n",
      "Epoch 13, Loss: 0.12097867174168765\n",
      "Epoch 14, Loss: 0.11950251148582178\n",
      "Epoch 15, Loss: 0.11922834194817786\n",
      "Epoch 16, Loss: 0.12050483102178842\n",
      "Epoch 17, Loss: 0.1182730343550612\n",
      "Epoch 18, Loss: 0.11729386053179618\n",
      "Epoch 19, Loss: 0.11768761007799267\n",
      "After interaction 4, reward = 110.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.13025596056971253\n",
      "Epoch 1, Loss: 0.12324742081633025\n",
      "Epoch 2, Loss: 0.12176062790543268\n",
      "Epoch 3, Loss: 0.12051357795889868\n",
      "Epoch 4, Loss: 0.11974270071424366\n",
      "Epoch 5, Loss: 0.11935336627600866\n",
      "Epoch 6, Loss: 0.12056286686487745\n",
      "Epoch 7, Loss: 0.11832958221007762\n",
      "Epoch 8, Loss: 0.11839046101108122\n",
      "Epoch 9, Loss: 0.11664883097250496\n",
      "Epoch 10, Loss: 0.11704714703217647\n",
      "Epoch 11, Loss: 0.11684500828884435\n",
      "Epoch 12, Loss: 0.11616111147489273\n",
      "Epoch 13, Loss: 0.1159160978486093\n",
      "Epoch 14, Loss: 0.11693611783844432\n",
      "Epoch 15, Loss: 0.11618484171668879\n",
      "Epoch 16, Loss: 0.1155768937685273\n",
      "Epoch 17, Loss: 0.1146731995153085\n",
      "Epoch 18, Loss: 0.11369086270839975\n",
      "Epoch 19, Loss: 0.11413623941572089\n",
      "After interaction 5, reward = 180.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.12539119720916778\n",
      "Epoch 1, Loss: 0.11952359244967509\n",
      "Epoch 2, Loss: 0.115964067261523\n",
      "Epoch 3, Loss: 0.11507631415244682\n",
      "Epoch 4, Loss: 0.11445552123261304\n",
      "Epoch 5, Loss: 0.11386817123376584\n",
      "Epoch 6, Loss: 0.1127767104958792\n",
      "Epoch 7, Loss: 0.11205569455944692\n",
      "Epoch 8, Loss: 0.11205502704388658\n",
      "Epoch 9, Loss: 0.11097397879567197\n",
      "Epoch 10, Loss: 0.11115355115561258\n",
      "Epoch 11, Loss: 0.110154164349398\n",
      "Epoch 12, Loss: 0.1096303015031756\n",
      "Epoch 13, Loss: 0.10931026615503807\n",
      "Epoch 14, Loss: 0.10902775773331255\n",
      "Epoch 15, Loss: 0.10863904376107487\n",
      "Epoch 16, Loss: 0.10786179986463347\n",
      "Epoch 17, Loss: 0.10768655683374136\n",
      "Epoch 18, Loss: 0.10634085756506727\n",
      "Epoch 19, Loss: 0.10760212463793606\n",
      "After interaction 6, reward = 55.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.12010957081340003\n",
      "Epoch 1, Loss: 0.11382120849554986\n",
      "Epoch 2, Loss: 0.11190582815369896\n",
      "Epoch 3, Loss: 0.11144197503285469\n",
      "Epoch 4, Loss: 0.11128614262747004\n",
      "Epoch 5, Loss: 0.10953851077699726\n",
      "Epoch 6, Loss: 0.10883071039587078\n",
      "Epoch 7, Loss: 0.10876556327210653\n",
      "Epoch 8, Loss: 0.10816302346227774\n",
      "Epoch 9, Loss: 0.10729366989661848\n",
      "Epoch 10, Loss: 0.10667103456037227\n",
      "Epoch 11, Loss: 0.10673750066936434\n",
      "Epoch 12, Loss: 0.10676798468534424\n",
      "Epoch 13, Loss: 0.10622226740813703\n",
      "Epoch 14, Loss: 0.10528077528625221\n",
      "Epoch 15, Loss: 0.10583852043342946\n",
      "Epoch 16, Loss: 0.10556159626331206\n",
      "Epoch 17, Loss: 0.10468553086157813\n",
      "Epoch 18, Loss: 0.1042113791853897\n",
      "Epoch 19, Loss: 0.10339705864181892\n",
      "After interaction 7, reward = 60.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.11479087713997461\n",
      "Epoch 1, Loss: 0.10901738005262163\n",
      "Epoch 2, Loss: 0.1067492189698683\n",
      "Epoch 3, Loss: 0.10628344732354505\n",
      "Epoch 4, Loss: 0.10592031044109801\n",
      "Epoch 5, Loss: 0.10487545024625282\n",
      "Epoch 6, Loss: 0.1044413589640944\n",
      "Epoch 7, Loss: 0.10438202146877375\n",
      "Epoch 8, Loss: 0.10462584855624862\n",
      "Epoch 9, Loss: 0.10423324180338052\n",
      "Epoch 10, Loss: 0.10284838910932255\n",
      "Epoch 11, Loss: 0.102279369689134\n",
      "Epoch 12, Loss: 0.10242264857786651\n",
      "Epoch 13, Loss: 0.10212812554756999\n",
      "Epoch 14, Loss: 0.10216796028420812\n",
      "Epoch 15, Loss: 0.10118900383772299\n",
      "Epoch 16, Loss: 0.10115426879125343\n",
      "Epoch 17, Loss: 0.10114460801419277\n",
      "Epoch 18, Loss: 0.100706073132685\n",
      "Epoch 19, Loss: 0.10035004350956737\n",
      "After interaction 8, reward = 130.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.1151876170083716\n",
      "Epoch 1, Loss: 0.10802525498804702\n",
      "Epoch 2, Loss: 0.10722495252726542\n",
      "Epoch 3, Loss: 0.1060809856386842\n",
      "Epoch 4, Loss: 0.1059769157644463\n",
      "Epoch 5, Loss: 0.10590946171800072\n",
      "Epoch 6, Loss: 0.10487953591663798\n",
      "Epoch 7, Loss: 0.10415991126509629\n",
      "Epoch 8, Loss: 0.10342847694858022\n",
      "Epoch 9, Loss: 0.10300541726421744\n",
      "Epoch 10, Loss: 0.10272598450608121\n",
      "Epoch 11, Loss: 0.10202099681871157\n",
      "Epoch 12, Loss: 0.10192714831875228\n",
      "Epoch 13, Loss: 0.10210829233420096\n",
      "Epoch 14, Loss: 0.10154804056778251\n",
      "Epoch 15, Loss: 0.10095204468745747\n",
      "Epoch 16, Loss: 0.10050279975897239\n",
      "Epoch 17, Loss: 0.09977493096788041\n",
      "Epoch 18, Loss: 0.09938601037089381\n",
      "Epoch 19, Loss: 0.09898934667949891\n",
      "After interaction 9, reward = 55.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.11159381889470539\n",
      "Epoch 1, Loss: 0.10627839943339164\n",
      "Epoch 2, Loss: 0.10550435746195053\n",
      "Epoch 3, Loss: 0.10424664309998233\n",
      "Epoch 4, Loss: 0.10374024998173964\n",
      "Epoch 5, Loss: 0.10305388921296088\n",
      "Epoch 6, Loss: 0.10190916886203827\n",
      "Epoch 7, Loss: 0.10215928177822368\n",
      "Epoch 8, Loss: 0.10298422467722328\n",
      "Epoch 9, Loss: 0.10231314352306368\n",
      "Epoch 10, Loss: 0.1023610532185636\n",
      "Epoch 11, Loss: 0.10127094805991456\n",
      "Epoch 12, Loss: 0.1012575480318356\n",
      "Epoch 13, Loss: 0.10111247422534003\n",
      "Epoch 14, Loss: 0.10053537926479754\n",
      "Epoch 15, Loss: 0.09957370535950086\n",
      "Epoch 16, Loss: 0.09884687085069621\n",
      "Epoch 17, Loss: 0.09942337775149927\n",
      "Epoch 18, Loss: 0.09919502935406797\n",
      "Epoch 19, Loss: 0.0986583791262193\n",
      "After interaction 10, reward = 35.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.10860379775546639\n",
      "Epoch 1, Loss: 0.10377309995064089\n",
      "Epoch 2, Loss: 0.1028562840193374\n",
      "Epoch 3, Loss: 0.10245845464130515\n",
      "Epoch 4, Loss: 0.102037838731908\n",
      "Epoch 5, Loss: 0.10201066571827892\n",
      "Epoch 6, Loss: 0.10169998137011013\n",
      "Epoch 7, Loss: 0.10085648532781064\n",
      "Epoch 8, Loss: 0.10073653304413574\n",
      "Epoch 9, Loss: 0.10026167554035216\n",
      "Epoch 10, Loss: 0.10051257589681689\n",
      "Epoch 11, Loss: 0.10031564780021911\n",
      "Epoch 12, Loss: 0.09964468114679081\n",
      "Epoch 13, Loss: 0.10030794486834396\n",
      "Epoch 14, Loss: 0.10012240185313029\n",
      "Epoch 15, Loss: 0.09853594318780724\n",
      "Epoch 16, Loss: 0.09849619662879627\n",
      "Epoch 17, Loss: 0.0977083618238092\n",
      "Epoch 18, Loss: 0.0975273644747255\n",
      "Epoch 19, Loss: 0.09758613461138088\n",
      "After interaction 11, reward = 120.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.11013291899478127\n",
      "Epoch 1, Loss: 0.1045361028167457\n",
      "Epoch 2, Loss: 0.1035375313502374\n",
      "Epoch 3, Loss: 0.10302410776306908\n",
      "Epoch 4, Loss: 0.10259395258294211\n",
      "Epoch 5, Loss: 0.10282684446935565\n",
      "Epoch 6, Loss: 0.10232218726177555\n",
      "Epoch 7, Loss: 0.10202619375319699\n",
      "Epoch 8, Loss: 0.10181919654826381\n",
      "Epoch 9, Loss: 0.10221991940189754\n",
      "Epoch 10, Loss: 0.10113849750395572\n",
      "Epoch 11, Loss: 0.10083697746598384\n",
      "Epoch 12, Loss: 0.10110999973389292\n",
      "Epoch 13, Loss: 0.10063819383422319\n",
      "Epoch 14, Loss: 0.09995971052892033\n",
      "Epoch 15, Loss: 0.0993907797649112\n",
      "Epoch 16, Loss: 0.09969729776479348\n",
      "Epoch 17, Loss: 0.09896735694036683\n",
      "Epoch 18, Loss: 0.09895756390715195\n",
      "Epoch 19, Loss: 0.09869054641550333\n",
      "After interaction 12, reward = 165.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.11079482945909766\n",
      "Epoch 1, Loss: 0.10658428225952274\n",
      "Epoch 2, Loss: 0.10578494703959848\n",
      "Epoch 3, Loss: 0.10372343712884668\n",
      "Epoch 4, Loss: 0.10363285300709077\n",
      "Epoch 5, Loss: 0.10312324112368486\n",
      "Epoch 6, Loss: 0.10253990348707048\n",
      "Epoch 7, Loss: 0.10156935651007583\n",
      "Epoch 8, Loss: 0.10130350753768967\n",
      "Epoch 9, Loss: 0.10049599771604224\n",
      "Epoch 10, Loss: 0.10038276705315201\n",
      "Epoch 11, Loss: 0.10082442836384711\n",
      "Epoch 12, Loss: 0.09984580502434005\n",
      "Epoch 13, Loss: 0.09941160250250863\n",
      "Epoch 14, Loss: 0.09911968080644475\n",
      "Epoch 15, Loss: 0.0983876484192737\n",
      "Epoch 16, Loss: 0.09789225865426592\n",
      "Epoch 17, Loss: 0.09752872925723419\n",
      "Epoch 18, Loss: 0.09772621804582751\n",
      "Epoch 19, Loss: 0.0976884018848924\n",
      "After interaction 13, reward = 120.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.10933817162565343\n",
      "Epoch 1, Loss: 0.10488266533093686\n",
      "Epoch 2, Loss: 0.10460419082966556\n",
      "Epoch 3, Loss: 0.10297404347402972\n",
      "Epoch 4, Loss: 0.10227709144350453\n",
      "Epoch 5, Loss: 0.10201657518049843\n",
      "Epoch 6, Loss: 0.101171444853602\n",
      "Epoch 7, Loss: 0.1008842455944495\n",
      "Epoch 8, Loss: 0.10078631525097836\n",
      "Epoch 9, Loss: 0.10026084002849368\n",
      "Epoch 10, Loss: 0.09983304648304597\n",
      "Epoch 11, Loss: 0.09981524806404397\n",
      "Epoch 12, Loss: 0.10000986385804218\n",
      "Epoch 13, Loss: 0.09937903084063118\n",
      "Epoch 14, Loss: 0.09869075820827905\n",
      "Epoch 15, Loss: 0.09837452785015216\n",
      "Epoch 16, Loss: 0.09828740085708004\n",
      "Epoch 17, Loss: 0.09679327715905504\n",
      "Epoch 18, Loss: 0.09727868013397113\n",
      "Epoch 19, Loss: 0.09656110718844614\n",
      "After interaction 14, reward = 255.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.11135484932543557\n",
      "Epoch 1, Loss: 0.10509324103802997\n",
      "Epoch 2, Loss: 0.10304858973650514\n",
      "Epoch 3, Loss: 0.10168892046179562\n",
      "Epoch 4, Loss: 0.1011283496151668\n",
      "Epoch 5, Loss: 0.10000959174619808\n",
      "Epoch 6, Loss: 0.10027236657187019\n",
      "Epoch 7, Loss: 0.0991362285438492\n",
      "Epoch 8, Loss: 0.09872334517327103\n",
      "Epoch 9, Loss: 0.09839923069216011\n",
      "Epoch 10, Loss: 0.09867942833109845\n",
      "Epoch 11, Loss: 0.09730867914800156\n",
      "Epoch 12, Loss: 0.09732661423851352\n",
      "Epoch 13, Loss: 0.09719637055270197\n",
      "Epoch 14, Loss: 0.096705053562842\n",
      "Epoch 15, Loss: 0.09664809414322094\n",
      "Epoch 16, Loss: 0.0958141999789262\n",
      "Epoch 17, Loss: 0.09515126643988672\n",
      "Epoch 18, Loss: 0.09528026380749081\n",
      "Epoch 19, Loss: 0.09482657136900502\n",
      "After interaction 15, reward = 85.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.10399811360472515\n",
      "Epoch 1, Loss: 0.10056920883748112\n",
      "Epoch 2, Loss: 0.09959086154570365\n",
      "Epoch 3, Loss: 0.0987710480813795\n",
      "Epoch 4, Loss: 0.09862518330486235\n",
      "Epoch 5, Loss: 0.09833532486699277\n",
      "Epoch 6, Loss: 0.09774089042944051\n",
      "Epoch 7, Loss: 0.09733300948992253\n",
      "Epoch 8, Loss: 0.09660079657099088\n",
      "Epoch 9, Loss: 0.09646778357419886\n",
      "Epoch 10, Loss: 0.09557714479523607\n",
      "Epoch 11, Loss: 0.09581443761211048\n",
      "Epoch 12, Loss: 0.09532225706017426\n",
      "Epoch 13, Loss: 0.09538875025396207\n",
      "Epoch 14, Loss: 0.09455560285652803\n",
      "Epoch 15, Loss: 0.09387498527563072\n",
      "Epoch 16, Loss: 0.09378608919138105\n",
      "Epoch 17, Loss: 0.0937671274693786\n",
      "Epoch 18, Loss: 0.09367035433812902\n",
      "Epoch 19, Loss: 0.0928828625764615\n",
      "After interaction 16, reward = 200.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.1049775496315635\n",
      "Epoch 1, Loss: 0.10005983868409594\n",
      "Epoch 2, Loss: 0.09866287286773368\n",
      "Epoch 3, Loss: 0.09775641445920291\n",
      "Epoch 4, Loss: 0.09825595820162132\n",
      "Epoch 5, Loss: 0.09715792416440372\n",
      "Epoch 6, Loss: 0.09656983895471441\n",
      "Epoch 7, Loss: 0.09599203204932638\n",
      "Epoch 8, Loss: 0.09588419691955584\n",
      "Epoch 9, Loss: 0.09545600174972377\n",
      "Epoch 10, Loss: 0.0943704959943677\n",
      "Epoch 11, Loss: 0.09408921290892143\n",
      "Epoch 12, Loss: 0.09384090276996288\n",
      "Epoch 13, Loss: 0.0935093319206591\n",
      "Epoch 14, Loss: 0.0931107435890727\n",
      "Epoch 15, Loss: 0.09245175052324203\n",
      "Epoch 16, Loss: 0.09277092945522192\n",
      "Epoch 17, Loss: 0.09242136632221759\n",
      "Epoch 18, Loss: 0.09236290047893744\n",
      "Epoch 19, Loss: 0.09188699956061494\n",
      "After interaction 17, reward = 140.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.10042413628119672\n",
      "Epoch 1, Loss: 0.09734923691111964\n",
      "Epoch 2, Loss: 0.09613974476430509\n",
      "Epoch 3, Loss: 0.09567042551675559\n",
      "Epoch 4, Loss: 0.09507831702931879\n",
      "Epoch 5, Loss: 0.09503738415186275\n",
      "Epoch 6, Loss: 0.09477868159430407\n",
      "Epoch 7, Loss: 0.09398774901045466\n",
      "Epoch 8, Loss: 0.09350189304919791\n",
      "Epoch 9, Loss: 0.09299954964618547\n",
      "Epoch 10, Loss: 0.09336956723369724\n",
      "Epoch 11, Loss: 0.09298827413808873\n",
      "Epoch 12, Loss: 0.0922156824246519\n",
      "Epoch 13, Loss: 0.09294586309485404\n",
      "Epoch 14, Loss: 0.09217448328507022\n",
      "Epoch 15, Loss: 0.09127926206298485\n",
      "Epoch 16, Loss: 0.09098287994369607\n",
      "Epoch 17, Loss: 0.09107776435929543\n",
      "Epoch 18, Loss: 0.09049574098667461\n",
      "Epoch 19, Loss: 0.09040221104106362\n",
      "After interaction 18, reward = 95.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.09601461578756373\n",
      "Epoch 1, Loss: 0.09290827328875599\n",
      "Epoch 2, Loss: 0.09266298803163188\n",
      "Epoch 3, Loss: 0.0925787747557982\n",
      "Epoch 4, Loss: 0.09255361289843937\n",
      "Epoch 5, Loss: 0.09205797879471142\n",
      "Epoch 6, Loss: 0.09134003298051391\n",
      "Epoch 7, Loss: 0.09073247448805652\n",
      "Epoch 8, Loss: 0.0909214677600365\n",
      "Epoch 9, Loss: 0.09038017054338662\n",
      "Epoch 10, Loss: 0.08987268665034964\n",
      "Epoch 11, Loss: 0.09025640633823358\n",
      "Epoch 12, Loss: 0.08967080637945733\n",
      "Epoch 13, Loss: 0.08990938646478233\n",
      "Epoch 14, Loss: 0.0898698310615262\n",
      "Epoch 15, Loss: 0.08916389362583124\n",
      "Epoch 16, Loss: 0.08835112295450424\n",
      "Epoch 17, Loss: 0.08861939843281308\n",
      "Epoch 18, Loss: 0.08828714560894739\n",
      "Epoch 19, Loss: 0.08773673161404733\n",
      "After interaction 19, reward = 90.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.09387584303942076\n",
      "Epoch 1, Loss: 0.09169983894272843\n",
      "Epoch 2, Loss: 0.09030466436086539\n",
      "Epoch 3, Loss: 0.0903538087237923\n",
      "Epoch 4, Loss: 0.09042527003098771\n",
      "Epoch 5, Loss: 0.0896187624401062\n",
      "Epoch 6, Loss: 0.08948316807946695\n",
      "Epoch 7, Loss: 0.09011721753235045\n",
      "Epoch 8, Loss: 0.08890643180341035\n",
      "Epoch 9, Loss: 0.08914204425565385\n",
      "Epoch 10, Loss: 0.0888669233721404\n",
      "Epoch 11, Loss: 0.08847001369608148\n",
      "Epoch 12, Loss: 0.08792513917799391\n",
      "Epoch 13, Loss: 0.08709829221314329\n",
      "Epoch 14, Loss: 0.08756118252886753\n",
      "Epoch 15, Loss: 0.08767853471287464\n",
      "Epoch 16, Loss: 0.08778915003435384\n",
      "Epoch 17, Loss: 0.08744740535030428\n",
      "Epoch 18, Loss: 0.08653407289693507\n",
      "Epoch 19, Loss: 0.08634616625893837\n",
      "After interaction 20, reward = 135.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.0915933773502127\n",
      "Epoch 1, Loss: 0.08958557326814313\n",
      "Epoch 2, Loss: 0.0888238821925883\n",
      "Epoch 3, Loss: 0.08854177861029623\n",
      "Epoch 4, Loss: 0.0889904876894077\n",
      "Epoch 5, Loss: 0.08828958653956437\n",
      "Epoch 6, Loss: 0.08827207294678448\n",
      "Epoch 7, Loss: 0.08760650892235328\n",
      "Epoch 8, Loss: 0.08725531850370322\n",
      "Epoch 9, Loss: 0.08750120723703379\n",
      "Epoch 10, Loss: 0.08711064913959214\n",
      "Epoch 11, Loss: 0.08759259583716096\n",
      "Epoch 12, Loss: 0.08654171804243008\n",
      "Epoch 13, Loss: 0.08720360189934313\n",
      "Epoch 14, Loss: 0.08707905515146806\n",
      "Epoch 15, Loss: 0.08554248991509708\n",
      "Epoch 16, Loss: 0.08638756137776685\n",
      "Epoch 17, Loss: 0.08576835307035956\n",
      "Epoch 18, Loss: 0.08558859951783396\n",
      "Epoch 19, Loss: 0.08575093664691218\n",
      "After interaction 21, reward = 205.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.09497076766055988\n",
      "Epoch 1, Loss: 0.09105339618432365\n",
      "Epoch 2, Loss: 0.09094412516821622\n",
      "Epoch 3, Loss: 0.09036618170191162\n",
      "Epoch 4, Loss: 0.0895995913157242\n",
      "Epoch 5, Loss: 0.08909476255108102\n",
      "Epoch 6, Loss: 0.08874789570997552\n",
      "Epoch 7, Loss: 0.08815401859784248\n",
      "Epoch 8, Loss: 0.08788327132915108\n",
      "Epoch 9, Loss: 0.08769548803616072\n",
      "Epoch 10, Loss: 0.08675560628233879\n",
      "Epoch 11, Loss: 0.08665829490568078\n",
      "Epoch 12, Loss: 0.08741504920240491\n",
      "Epoch 13, Loss: 0.0863019967819603\n",
      "Epoch 14, Loss: 0.08596870222042848\n",
      "Epoch 15, Loss: 0.08583136580079369\n",
      "Epoch 16, Loss: 0.08595641069385247\n",
      "Epoch 17, Loss: 0.08497292777496797\n",
      "Epoch 18, Loss: 0.08510807994376678\n",
      "Epoch 19, Loss: 0.08518208437444899\n",
      "After interaction 22, reward = 155.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.09237590788542868\n",
      "Epoch 1, Loss: 0.08935077718444173\n",
      "Epoch 2, Loss: 0.08864864560872318\n",
      "Epoch 3, Loss: 0.08855355912480287\n",
      "Epoch 4, Loss: 0.08817078414190449\n",
      "Epoch 5, Loss: 0.08792581720602048\n",
      "Epoch 6, Loss: 0.08797114503456768\n",
      "Epoch 7, Loss: 0.08677594584952569\n",
      "Epoch 8, Loss: 0.08676626576823736\n",
      "Epoch 9, Loss: 0.08678041445237943\n",
      "Epoch 10, Loss: 0.08559105134583886\n",
      "Epoch 11, Loss: 0.08593305751892875\n",
      "Epoch 12, Loss: 0.08557927893600215\n",
      "Epoch 13, Loss: 0.0856278362880363\n",
      "Epoch 14, Loss: 0.08587382801928609\n",
      "Epoch 15, Loss: 0.08533911501759393\n",
      "Epoch 16, Loss: 0.08507898751376582\n",
      "Epoch 17, Loss: 0.08449154513738913\n",
      "Epoch 18, Loss: 0.08464598192881166\n",
      "Epoch 19, Loss: 0.08434417222482266\n",
      "After interaction 23, reward = 20.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08794527716837532\n",
      "Epoch 1, Loss: 0.08612643567137158\n",
      "Epoch 2, Loss: 0.08547066268674589\n",
      "Epoch 3, Loss: 0.08510901062275725\n",
      "Epoch 4, Loss: 0.08534457458327024\n",
      "Epoch 5, Loss: 0.08522665424416273\n",
      "Epoch 6, Loss: 0.0847982979690658\n",
      "Epoch 7, Loss: 0.08498876634518146\n",
      "Epoch 8, Loss: 0.08503831367016795\n",
      "Epoch 9, Loss: 0.08478977898118967\n",
      "Epoch 10, Loss: 0.0844351571191517\n",
      "Epoch 11, Loss: 0.08424040792489362\n",
      "Epoch 12, Loss: 0.08385546836505084\n",
      "Epoch 13, Loss: 0.08416997641324997\n",
      "Epoch 14, Loss: 0.08360333951449801\n",
      "Epoch 15, Loss: 0.08370454036962305\n",
      "Epoch 16, Loss: 0.08321434667440451\n",
      "Epoch 17, Loss: 0.08321113344151135\n",
      "Epoch 18, Loss: 0.08288340005975071\n",
      "Epoch 19, Loss: 0.08196808515096021\n",
      "After interaction 24, reward = 185.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08980170270375046\n",
      "Epoch 1, Loss: 0.08733262602081802\n",
      "Epoch 2, Loss: 0.08714424384362986\n",
      "Epoch 3, Loss: 0.08641996836072256\n",
      "Epoch 4, Loss: 0.08658714033229815\n",
      "Epoch 5, Loss: 0.0860883310780412\n",
      "Epoch 6, Loss: 0.08557763946233128\n",
      "Epoch 7, Loss: 0.08556501655388976\n",
      "Epoch 8, Loss: 0.0849208254995071\n",
      "Epoch 9, Loss: 0.08481787741130886\n",
      "Epoch 10, Loss: 0.08477299764029514\n",
      "Epoch 11, Loss: 0.08447343969817761\n",
      "Epoch 12, Loss: 0.08434047270638469\n",
      "Epoch 13, Loss: 0.08392972949127842\n",
      "Epoch 14, Loss: 0.08417437450311314\n",
      "Epoch 15, Loss: 0.08398684170767305\n",
      "Epoch 16, Loss: 0.0835291918106406\n",
      "Epoch 17, Loss: 0.08320990115585514\n",
      "Epoch 18, Loss: 0.08306330957065029\n",
      "Epoch 19, Loss: 0.08233161257725853\n",
      "After interaction 25, reward = 45.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08747938841600315\n",
      "Epoch 1, Loss: 0.08514945850610098\n",
      "Epoch 2, Loss: 0.08531889098416007\n",
      "Epoch 3, Loss: 0.08535281066527267\n",
      "Epoch 4, Loss: 0.08496333038151233\n",
      "Epoch 5, Loss: 0.08454799548452854\n",
      "Epoch 6, Loss: 0.08462357750209584\n",
      "Epoch 7, Loss: 0.08406801037949535\n",
      "Epoch 8, Loss: 0.08438476254012076\n",
      "Epoch 9, Loss: 0.0846437923530449\n",
      "Epoch 10, Loss: 0.08380940179621053\n",
      "Epoch 11, Loss: 0.08354773636271187\n",
      "Epoch 12, Loss: 0.08349020263917067\n",
      "Epoch 13, Loss: 0.08360131060430058\n",
      "Epoch 14, Loss: 0.08325360899099245\n",
      "Epoch 15, Loss: 0.08282941888689505\n",
      "Epoch 16, Loss: 0.08282983471043345\n",
      "Epoch 17, Loss: 0.08228104234071154\n",
      "Epoch 18, Loss: 0.08225621029197408\n",
      "Epoch 19, Loss: 0.08201168817103402\n",
      "After interaction 26, reward = 5.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08637109387492596\n",
      "Epoch 1, Loss: 0.08406726856620086\n",
      "Epoch 2, Loss: 0.08417514684884606\n",
      "Epoch 3, Loss: 0.08382990781948159\n",
      "Epoch 4, Loss: 0.08401703720746827\n",
      "Epoch 5, Loss: 0.08378234679591336\n",
      "Epoch 6, Loss: 0.08333735196521487\n",
      "Epoch 7, Loss: 0.08316880918776536\n",
      "Epoch 8, Loss: 0.08377195070131205\n",
      "Epoch 9, Loss: 0.08300185867820371\n",
      "Epoch 10, Loss: 0.08275830716861488\n",
      "Epoch 11, Loss: 0.0827717676708325\n",
      "Epoch 12, Loss: 0.08256193618470085\n",
      "Epoch 13, Loss: 0.08226062358224341\n",
      "Epoch 14, Loss: 0.08209543534915774\n",
      "Epoch 15, Loss: 0.08207243023201172\n",
      "Epoch 16, Loss: 0.08165211169188383\n",
      "Epoch 17, Loss: 0.08207691258494709\n",
      "Epoch 18, Loss: 0.08189312524200326\n",
      "Epoch 19, Loss: 0.0809483212156928\n",
      "After interaction 27, reward = 35.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08834199612977256\n",
      "Epoch 1, Loss: 0.08634839029832984\n",
      "Epoch 2, Loss: 0.08580813689049804\n",
      "Epoch 3, Loss: 0.08551365321217506\n",
      "Epoch 4, Loss: 0.08508937163456388\n",
      "Epoch 5, Loss: 0.08446100153826967\n",
      "Epoch 6, Loss: 0.08427405276673434\n",
      "Epoch 7, Loss: 0.08395571720364961\n",
      "Epoch 8, Loss: 0.08378853275545323\n",
      "Epoch 9, Loss: 0.08387118798809186\n",
      "Epoch 10, Loss: 0.08408783674127207\n",
      "Epoch 11, Loss: 0.0835000040830101\n",
      "Epoch 12, Loss: 0.08305509460948533\n",
      "Epoch 13, Loss: 0.083932550565443\n",
      "Epoch 14, Loss: 0.08312323445745275\n",
      "Epoch 15, Loss: 0.08273181645655817\n",
      "Epoch 16, Loss: 0.08266672039758452\n",
      "Epoch 17, Loss: 0.08274831424568124\n",
      "Epoch 18, Loss: 0.08219243187586157\n",
      "Epoch 19, Loss: 0.08214168324393163\n",
      "After interaction 28, reward = 110.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.0870926923312744\n",
      "Epoch 1, Loss: 0.08537834812297754\n",
      "Epoch 2, Loss: 0.08484480288008271\n",
      "Epoch 3, Loss: 0.08423225096836172\n",
      "Epoch 4, Loss: 0.08456648397030528\n",
      "Epoch 5, Loss: 0.08428105336992443\n",
      "Epoch 6, Loss: 0.08381016904796375\n",
      "Epoch 7, Loss: 0.08407315499948123\n",
      "Epoch 8, Loss: 0.08420998961998813\n",
      "Epoch 9, Loss: 0.0830486891247742\n",
      "Epoch 10, Loss: 0.08304611183788656\n",
      "Epoch 11, Loss: 0.08341901117763965\n",
      "Epoch 12, Loss: 0.08250522954185696\n",
      "Epoch 13, Loss: 0.08244326023146888\n",
      "Epoch 14, Loss: 0.08256401307530245\n",
      "Epoch 15, Loss: 0.08216015944992541\n",
      "Epoch 16, Loss: 0.08198240509070105\n",
      "Epoch 17, Loss: 0.08232669920178044\n",
      "Epoch 18, Loss: 0.08147789914409527\n",
      "Epoch 19, Loss: 0.0815217672930779\n",
      "After interaction 29, reward = 155.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08746690034625627\n",
      "Epoch 1, Loss: 0.08504086831553545\n",
      "Epoch 2, Loss: 0.08513314832661983\n",
      "Epoch 3, Loss: 0.08500371479976063\n",
      "Epoch 4, Loss: 0.08500422140840086\n",
      "Epoch 5, Loss: 0.08409429386686881\n",
      "Epoch 6, Loss: 0.08433502350324094\n",
      "Epoch 7, Loss: 0.08380946485172433\n",
      "Epoch 8, Loss: 0.08334427991188999\n",
      "Epoch 9, Loss: 0.0834859637856664\n",
      "Epoch 10, Loss: 0.08330194526086367\n",
      "Epoch 11, Loss: 0.0832243640605757\n",
      "Epoch 12, Loss: 0.08340455522400632\n",
      "Epoch 13, Loss: 0.08233846789775985\n",
      "Epoch 14, Loss: 0.08291815619075135\n",
      "Epoch 15, Loss: 0.08242169504045899\n",
      "Epoch 16, Loss: 0.08213955459346198\n",
      "Epoch 17, Loss: 0.08195954988560612\n",
      "Epoch 18, Loss: 0.08219301094240399\n",
      "Epoch 19, Loss: 0.08160949800048796\n",
      "After interaction 30, reward = 125.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08664597966075527\n",
      "Epoch 1, Loss: 0.08496066194504703\n",
      "Epoch 2, Loss: 0.08478960214676162\n",
      "Epoch 3, Loss: 0.08447237288613939\n",
      "Epoch 4, Loss: 0.08434178180125917\n",
      "Epoch 5, Loss: 0.08382672939890175\n",
      "Epoch 6, Loss: 0.08373273571885809\n",
      "Epoch 7, Loss: 0.08340440733487539\n",
      "Epoch 8, Loss: 0.08327301912672476\n",
      "Epoch 9, Loss: 0.08322550496368697\n",
      "Epoch 10, Loss: 0.0831198359296119\n",
      "Epoch 11, Loss: 0.08293453569461173\n",
      "Epoch 12, Loss: 0.08243423045147666\n",
      "Epoch 13, Loss: 0.0824049406212446\n",
      "Epoch 14, Loss: 0.08225295868641237\n",
      "Epoch 15, Loss: 0.08247076772291756\n",
      "Epoch 16, Loss: 0.08166032790088933\n",
      "Epoch 17, Loss: 0.08178442401969888\n",
      "Epoch 18, Loss: 0.08199207261714535\n",
      "Epoch 19, Loss: 0.08151434572269724\n",
      "After interaction 31, reward = 180.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08621013706303672\n",
      "Epoch 1, Loss: 0.08460770670766404\n",
      "Epoch 2, Loss: 0.08431974167160212\n",
      "Epoch 3, Loss: 0.08470299459398131\n",
      "Epoch 4, Loss: 0.08446531756645172\n",
      "Epoch 5, Loss: 0.08409983229686835\n",
      "Epoch 6, Loss: 0.08391963520559138\n",
      "Epoch 7, Loss: 0.08386061181620966\n",
      "Epoch 8, Loss: 0.08302909798437377\n",
      "Epoch 9, Loss: 0.08283405723321975\n",
      "Epoch 10, Loss: 0.08295748394099814\n",
      "Epoch 11, Loss: 0.08260644205244891\n",
      "Epoch 12, Loss: 0.08235899464860022\n",
      "Epoch 13, Loss: 0.08226670584824555\n",
      "Epoch 14, Loss: 0.08179068375645646\n",
      "Epoch 15, Loss: 0.08187974579477003\n",
      "Epoch 16, Loss: 0.08223160338778981\n",
      "Epoch 17, Loss: 0.08144267646764525\n",
      "Epoch 18, Loss: 0.08164859681124487\n",
      "Epoch 19, Loss: 0.08128047189327657\n",
      "After interaction 32, reward = 135.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08640919375952955\n",
      "Epoch 1, Loss: 0.08497199132118056\n",
      "Epoch 2, Loss: 0.08426852965980644\n",
      "Epoch 3, Loss: 0.08418244029368498\n",
      "Epoch 4, Loss: 0.0843006959736448\n",
      "Epoch 5, Loss: 0.08409135692033806\n",
      "Epoch 6, Loss: 0.08319652816873045\n",
      "Epoch 7, Loss: 0.08297050617262909\n",
      "Epoch 8, Loss: 0.08304046639473991\n",
      "Epoch 9, Loss: 0.08283540631571314\n",
      "Epoch 10, Loss: 0.08314094685689503\n",
      "Epoch 11, Loss: 0.08250381039412695\n",
      "Epoch 12, Loss: 0.08274887663564218\n",
      "Epoch 13, Loss: 0.08269384310857449\n",
      "Epoch 14, Loss: 0.08215585739172665\n",
      "Epoch 15, Loss: 0.08193347059388878\n",
      "Epoch 16, Loss: 0.08249523254555716\n",
      "Epoch 17, Loss: 0.08157696472046977\n",
      "Epoch 18, Loss: 0.08127540596155498\n",
      "Epoch 19, Loss: 0.08125213398874707\n",
      "After interaction 33, reward = 155.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08795111837280567\n",
      "Epoch 1, Loss: 0.08620170767234626\n",
      "Epoch 2, Loss: 0.0850796606199187\n",
      "Epoch 3, Loss: 0.0850276992099774\n",
      "Epoch 4, Loss: 0.08454065554921543\n",
      "Epoch 5, Loss: 0.08453217033455887\n",
      "Epoch 6, Loss: 0.08391793808730641\n",
      "Epoch 7, Loss: 0.08369955868295564\n",
      "Epoch 8, Loss: 0.08325137153348457\n",
      "Epoch 9, Loss: 0.08324382264034545\n",
      "Epoch 10, Loss: 0.08263926872546437\n",
      "Epoch 11, Loss: 0.08263618365827198\n",
      "Epoch 12, Loss: 0.08266743386885006\n",
      "Epoch 13, Loss: 0.08249037870237513\n",
      "Epoch 14, Loss: 0.08193740558583118\n",
      "Epoch 15, Loss: 0.08188073646260316\n",
      "Epoch 16, Loss: 0.08161306774739167\n",
      "Epoch 17, Loss: 0.0817294733347456\n",
      "Epoch 18, Loss: 0.08150007395260274\n",
      "Epoch 19, Loss: 0.0819305645846701\n",
      "After interaction 34, reward = 55.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08589954227808376\n",
      "Epoch 1, Loss: 0.08416802694124735\n",
      "Epoch 2, Loss: 0.08392503261674543\n",
      "Epoch 3, Loss: 0.08392638275420125\n",
      "Epoch 4, Loss: 0.08346416024343044\n",
      "Epoch 5, Loss: 0.08311108911423283\n",
      "Epoch 6, Loss: 0.08296757389853111\n",
      "Epoch 7, Loss: 0.08278310102111888\n",
      "Epoch 8, Loss: 0.0829256397007325\n",
      "Epoch 9, Loss: 0.08268136763815723\n",
      "Epoch 10, Loss: 0.08245998282805235\n",
      "Epoch 11, Loss: 0.08254192792861303\n",
      "Epoch 12, Loss: 0.08197935050067233\n",
      "Epoch 13, Loss: 0.08203956983540109\n",
      "Epoch 14, Loss: 0.08233172255196243\n",
      "Epoch 15, Loss: 0.0815895153235467\n",
      "Epoch 16, Loss: 0.081455692301111\n",
      "Epoch 17, Loss: 0.08121653629973495\n",
      "Epoch 18, Loss: 0.08094694274105697\n",
      "Epoch 19, Loss: 0.0808028476924394\n",
      "After interaction 35, reward = 100.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08466315940237758\n",
      "Epoch 1, Loss: 0.08294024202699482\n",
      "Epoch 2, Loss: 0.08310569928654564\n",
      "Epoch 3, Loss: 0.08258379108860912\n",
      "Epoch 4, Loss: 0.08240232655071894\n",
      "Epoch 5, Loss: 0.08255741480271307\n",
      "Epoch 6, Loss: 0.08222214027398685\n",
      "Epoch 7, Loss: 0.08206764281943014\n",
      "Epoch 8, Loss: 0.0820952604521164\n",
      "Epoch 9, Loss: 0.08184587137374333\n",
      "Epoch 10, Loss: 0.08214226678881824\n",
      "Epoch 11, Loss: 0.08120747226735765\n",
      "Epoch 12, Loss: 0.08080752740919382\n",
      "Epoch 13, Loss: 0.0810460736753154\n",
      "Epoch 14, Loss: 0.08101789874799926\n",
      "Epoch 15, Loss: 0.08111328022182675\n",
      "Epoch 16, Loss: 0.08040590776603493\n",
      "Epoch 17, Loss: 0.08075295977156847\n",
      "Epoch 18, Loss: 0.08045871228128179\n",
      "Epoch 19, Loss: 0.08032160524720847\n",
      "After interaction 36, reward = 165.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08520783031342215\n",
      "Epoch 1, Loss: 0.08379772570305306\n",
      "Epoch 2, Loss: 0.08412504054891055\n",
      "Epoch 3, Loss: 0.08344059267001648\n",
      "Epoch 4, Loss: 0.08294769073384425\n",
      "Epoch 5, Loss: 0.08279128056462924\n",
      "Epoch 6, Loss: 0.08267014496254199\n",
      "Epoch 7, Loss: 0.08252907746906293\n",
      "Epoch 8, Loss: 0.08228222860008398\n",
      "Epoch 9, Loss: 0.08205752075747477\n",
      "Epoch 10, Loss: 0.08179357939648177\n",
      "Epoch 11, Loss: 0.08204700605130737\n",
      "Epoch 12, Loss: 0.08161561983776805\n",
      "Epoch 13, Loss: 0.08152948622559637\n",
      "Epoch 14, Loss: 0.08073479586146734\n",
      "Epoch 15, Loss: 0.08099427348029575\n",
      "Epoch 16, Loss: 0.08118861400330035\n",
      "Epoch 17, Loss: 0.08102519257020308\n",
      "Epoch 18, Loss: 0.08064159781990067\n",
      "Epoch 19, Loss: 0.08073835036344267\n",
      "After interaction 37, reward = 155.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08486763351825899\n",
      "Epoch 1, Loss: 0.08320645192004723\n",
      "Epoch 2, Loss: 0.08279493210117973\n",
      "Epoch 3, Loss: 0.08293135105477252\n",
      "Epoch 4, Loss: 0.08238019706825048\n",
      "Epoch 5, Loss: 0.08271612820632807\n",
      "Epoch 6, Loss: 0.08211983657824005\n",
      "Epoch 7, Loss: 0.08184126857391717\n",
      "Epoch 8, Loss: 0.0818925596507943\n",
      "Epoch 9, Loss: 0.08163530074811007\n",
      "Epoch 10, Loss: 0.08149429920415174\n",
      "Epoch 11, Loss: 0.08164740213285775\n",
      "Epoch 12, Loss: 0.08125742719567572\n",
      "Epoch 13, Loss: 0.08078381191126295\n",
      "Epoch 14, Loss: 0.08086475322072646\n",
      "Epoch 15, Loss: 0.08103832746487875\n",
      "Epoch 16, Loss: 0.08073822885136027\n",
      "Epoch 17, Loss: 0.08037673577913387\n",
      "Epoch 18, Loss: 0.08036679005491468\n",
      "Epoch 19, Loss: 0.0804013432083063\n",
      "After interaction 38, reward = 175.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08564691754213696\n",
      "Epoch 1, Loss: 0.08379333824635296\n",
      "Epoch 2, Loss: 0.08371508369795355\n",
      "Epoch 3, Loss: 0.08289065050825443\n",
      "Epoch 4, Loss: 0.08278138389329642\n",
      "Epoch 5, Loss: 0.08205135255140954\n",
      "Epoch 6, Loss: 0.0820397446053587\n",
      "Epoch 7, Loss: 0.08172187772003443\n",
      "Epoch 8, Loss: 0.08188538823238176\n",
      "Epoch 9, Loss: 0.08140301172656796\n",
      "Epoch 10, Loss: 0.08113936102292069\n",
      "Epoch 11, Loss: 0.08091434115712563\n",
      "Epoch 12, Loss: 0.08077022448972115\n",
      "Epoch 13, Loss: 0.08016887100686172\n",
      "Epoch 14, Loss: 0.07998659483996913\n",
      "Epoch 15, Loss: 0.0800708003781906\n",
      "Epoch 16, Loss: 0.07965369273004509\n",
      "Epoch 17, Loss: 0.08000978556481103\n",
      "Epoch 18, Loss: 0.08002439701795366\n",
      "Epoch 19, Loss: 0.07968449188779363\n",
      "After interaction 39, reward = 80.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08285251276084431\n",
      "Epoch 1, Loss: 0.08164000301657881\n",
      "Epoch 2, Loss: 0.08125917810617575\n",
      "Epoch 3, Loss: 0.08177133505536137\n",
      "Epoch 4, Loss: 0.08137991701620374\n",
      "Epoch 5, Loss: 0.08092359813385677\n",
      "Epoch 6, Loss: 0.08045381554342483\n",
      "Epoch 7, Loss: 0.08084828016567613\n",
      "Epoch 8, Loss: 0.08033908862967434\n",
      "Epoch 9, Loss: 0.0803440288147886\n",
      "Epoch 10, Loss: 0.08029603969855331\n",
      "Epoch 11, Loss: 0.07996074945756965\n",
      "Epoch 12, Loss: 0.07975985757376998\n",
      "Epoch 13, Loss: 0.07948893585466964\n",
      "Epoch 14, Loss: 0.07944060156962807\n",
      "Epoch 15, Loss: 0.07922963723841175\n",
      "Epoch 16, Loss: 0.07917932224898139\n",
      "Epoch 17, Loss: 0.07897431770683429\n",
      "Epoch 18, Loss: 0.07892069604136599\n",
      "Epoch 19, Loss: 0.07904270615395084\n",
      "After interaction 40, reward = 155.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.0867122048454121\n",
      "Epoch 1, Loss: 0.08438453209116263\n",
      "Epoch 2, Loss: 0.08391957246905145\n",
      "Epoch 3, Loss: 0.0831329582788431\n",
      "Epoch 4, Loss: 0.08293283450175457\n",
      "Epoch 5, Loss: 0.08225953237324699\n",
      "Epoch 6, Loss: 0.08223336398605847\n",
      "Epoch 7, Loss: 0.08162971560100199\n",
      "Epoch 8, Loss: 0.08141976445848592\n",
      "Epoch 9, Loss: 0.08168997465528627\n",
      "Epoch 10, Loss: 0.08149714990576563\n",
      "Epoch 11, Loss: 0.08121240879966568\n",
      "Epoch 12, Loss: 0.08060309783743935\n",
      "Epoch 13, Loss: 0.08103592255853512\n",
      "Epoch 14, Loss: 0.08068667843655254\n",
      "Epoch 15, Loss: 0.08043443716752886\n",
      "Epoch 16, Loss: 0.07996303014391425\n",
      "Epoch 17, Loss: 0.07986861884710464\n",
      "Epoch 18, Loss: 0.08035778012210283\n",
      "Epoch 19, Loss: 0.07997223793213319\n",
      "After interaction 41, reward = 110.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08327417627575712\n",
      "Epoch 1, Loss: 0.0820365851807203\n",
      "Epoch 2, Loss: 0.08194637036738453\n",
      "Epoch 3, Loss: 0.08186818077426612\n",
      "Epoch 4, Loss: 0.08142569529585199\n",
      "Epoch 5, Loss: 0.08170730831448345\n",
      "Epoch 6, Loss: 0.0814087800787004\n",
      "Epoch 7, Loss: 0.08091160377153382\n",
      "Epoch 8, Loss: 0.0808724600022704\n",
      "Epoch 9, Loss: 0.08094156594619147\n",
      "Epoch 10, Loss: 0.08032250175401189\n",
      "Epoch 11, Loss: 0.0806018808254699\n",
      "Epoch 12, Loss: 0.08055361157918826\n",
      "Epoch 13, Loss: 0.08055771782311195\n",
      "Epoch 14, Loss: 0.07993373325822983\n",
      "Epoch 15, Loss: 0.08013575175807647\n",
      "Epoch 16, Loss: 0.07959979403622756\n",
      "Epoch 17, Loss: 0.07973501790392919\n",
      "Epoch 18, Loss: 0.07949761863340411\n",
      "Epoch 19, Loss: 0.07936301712319888\n",
      "After interaction 42, reward = 170.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.0859012573076104\n",
      "Epoch 1, Loss: 0.0839594333939589\n",
      "Epoch 2, Loss: 0.08356274622783212\n",
      "Epoch 3, Loss: 0.08296461147944742\n",
      "Epoch 4, Loss: 0.08286035432187516\n",
      "Epoch 5, Loss: 0.08283537280259232\n",
      "Epoch 6, Loss: 0.08244395821568477\n",
      "Epoch 7, Loss: 0.08177283703301587\n",
      "Epoch 8, Loss: 0.08187733209505269\n",
      "Epoch 9, Loss: 0.08141060072320706\n",
      "Epoch 10, Loss: 0.0816722842012935\n",
      "Epoch 11, Loss: 0.0808981816322101\n",
      "Epoch 12, Loss: 0.08065468720022716\n",
      "Epoch 13, Loss: 0.0810025000102157\n",
      "Epoch 14, Loss: 0.0806405204883802\n",
      "Epoch 15, Loss: 0.08111165014278196\n",
      "Epoch 16, Loss: 0.08008655522177802\n",
      "Epoch 17, Loss: 0.0801118392689074\n",
      "Epoch 18, Loss: 0.07999043661982702\n",
      "Epoch 19, Loss: 0.08014355569686189\n",
      "After interaction 43, reward = 230.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08465692952357505\n",
      "Epoch 1, Loss: 0.08340936485368611\n",
      "Epoch 2, Loss: 0.08320522918374874\n",
      "Epoch 3, Loss: 0.08279026559576393\n",
      "Epoch 4, Loss: 0.08272310407045523\n",
      "Epoch 5, Loss: 0.08193930725663451\n",
      "Epoch 6, Loss: 0.08185101713155243\n",
      "Epoch 7, Loss: 0.08215575909245625\n",
      "Epoch 8, Loss: 0.0819871982829652\n",
      "Epoch 9, Loss: 0.08121191334608713\n",
      "Epoch 10, Loss: 0.08102261635767923\n",
      "Epoch 11, Loss: 0.08092347099722229\n",
      "Epoch 12, Loss: 0.0806985266378376\n",
      "Epoch 13, Loss: 0.0811106191308929\n",
      "Epoch 14, Loss: 0.0805650060084595\n",
      "Epoch 15, Loss: 0.08039398601499217\n",
      "Epoch 16, Loss: 0.08065581202435688\n",
      "Epoch 17, Loss: 0.07999331743064043\n",
      "Epoch 18, Loss: 0.08018857541355187\n",
      "Epoch 19, Loss: 0.07970159853329391\n",
      "After interaction 44, reward = 30.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08255217645085285\n",
      "Epoch 1, Loss: 0.08164620127273732\n",
      "Epoch 2, Loss: 0.08140137133249294\n",
      "Epoch 3, Loss: 0.08120684730927695\n",
      "Epoch 4, Loss: 0.08130631989657694\n",
      "Epoch 5, Loss: 0.08079237797880204\n",
      "Epoch 6, Loss: 0.08039726298804842\n",
      "Epoch 7, Loss: 0.08041124109258561\n",
      "Epoch 8, Loss: 0.08032675095295934\n",
      "Epoch 9, Loss: 0.08027236499032378\n",
      "Epoch 10, Loss: 0.0798661023466069\n",
      "Epoch 11, Loss: 0.08021966531051809\n",
      "Epoch 12, Loss: 0.07995704487879643\n",
      "Epoch 13, Loss: 0.07977844741714922\n",
      "Epoch 14, Loss: 0.07971740515428527\n",
      "Epoch 15, Loss: 0.07928068060315238\n",
      "Epoch 16, Loss: 0.07929044487903335\n",
      "Epoch 17, Loss: 0.0790823418256678\n",
      "Epoch 18, Loss: 0.07868479598390914\n",
      "Epoch 19, Loss: 0.0789558938382419\n",
      "After interaction 45, reward = 105.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08209540697056898\n",
      "Epoch 1, Loss: 0.08070714443815842\n",
      "Epoch 2, Loss: 0.080642302080909\n",
      "Epoch 3, Loss: 0.08037582767286623\n",
      "Epoch 4, Loss: 0.0806264252589026\n",
      "Epoch 5, Loss: 0.08046299204684294\n",
      "Epoch 6, Loss: 0.08012472732823375\n",
      "Epoch 7, Loss: 0.07998267568014243\n",
      "Epoch 8, Loss: 0.08058583879049656\n",
      "Epoch 9, Loss: 0.07971791945003905\n",
      "Epoch 10, Loss: 0.07977132437769653\n",
      "Epoch 11, Loss: 0.0792435358582735\n",
      "Epoch 12, Loss: 0.07927749072034086\n",
      "Epoch 13, Loss: 0.07926174988093822\n",
      "Epoch 14, Loss: 0.07926061121341049\n",
      "Epoch 15, Loss: 0.07881940918860035\n",
      "Epoch 16, Loss: 0.07874816068466634\n",
      "Epoch 17, Loss: 0.07882949902202356\n",
      "Epoch 18, Loss: 0.078757280698337\n",
      "Epoch 19, Loss: 0.0781626865983415\n",
      "After interaction 46, reward = 95.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08050819016234519\n",
      "Epoch 1, Loss: 0.0799610958434346\n",
      "Epoch 2, Loss: 0.07963162678841217\n",
      "Epoch 3, Loss: 0.07941179667394803\n",
      "Epoch 4, Loss: 0.07933889221490999\n",
      "Epoch 5, Loss: 0.07960745272676491\n",
      "Epoch 6, Loss: 0.0790409388558811\n",
      "Epoch 7, Loss: 0.07931039558822224\n",
      "Epoch 8, Loss: 0.07905091340300623\n",
      "Epoch 9, Loss: 0.07897666571700229\n",
      "Epoch 10, Loss: 0.07880884835427426\n",
      "Epoch 11, Loss: 0.07861371908940627\n",
      "Epoch 12, Loss: 0.07848620942063911\n",
      "Epoch 13, Loss: 0.07831706704268787\n",
      "Epoch 14, Loss: 0.07886603867538838\n",
      "Epoch 15, Loss: 0.07843231069892315\n",
      "Epoch 16, Loss: 0.07781470434990075\n",
      "Epoch 17, Loss: 0.07809263613019488\n",
      "Epoch 18, Loss: 0.077605882528998\n",
      "Epoch 19, Loss: 0.07784948457461328\n",
      "After interaction 47, reward = 150.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.0817592503812935\n",
      "Epoch 1, Loss: 0.08106529927655687\n",
      "Epoch 2, Loss: 0.0802298051476818\n",
      "Epoch 3, Loss: 0.08050865549073608\n",
      "Epoch 4, Loss: 0.08069807097704562\n",
      "Epoch 5, Loss: 0.07985224410393921\n",
      "Epoch 6, Loss: 0.07983522028015028\n",
      "Epoch 7, Loss: 0.07986588028401763\n",
      "Epoch 8, Loss: 0.07951234070903718\n",
      "Epoch 9, Loss: 0.07937022148483676\n",
      "Epoch 10, Loss: 0.07926149666955007\n",
      "Epoch 11, Loss: 0.07928759338246175\n",
      "Epoch 12, Loss: 0.07911558150516454\n",
      "Epoch 13, Loss: 0.07890174353679077\n",
      "Epoch 14, Loss: 0.07840629831615484\n",
      "Epoch 15, Loss: 0.07866401735946058\n",
      "Epoch 16, Loss: 0.07825956389228192\n",
      "Epoch 17, Loss: 0.07839521664157263\n",
      "Epoch 18, Loss: 0.07850736103976604\n",
      "Epoch 19, Loss: 0.07804719774112857\n",
      "After interaction 48, reward = 520.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.0839790453047276\n",
      "Epoch 1, Loss: 0.08239885337659489\n",
      "Epoch 2, Loss: 0.08228333392357975\n",
      "Epoch 3, Loss: 0.08205971915862768\n",
      "Epoch 4, Loss: 0.08124774489372494\n",
      "Epoch 5, Loss: 0.08068282158232731\n",
      "Epoch 6, Loss: 0.08039270512641947\n",
      "Epoch 7, Loss: 0.08020833254288531\n",
      "Epoch 8, Loss: 0.08063996135147405\n",
      "Epoch 9, Loss: 0.08008450024883773\n",
      "Epoch 10, Loss: 0.07991079018831382\n",
      "Epoch 11, Loss: 0.07979512703576372\n",
      "Epoch 12, Loss: 0.07971151688839993\n",
      "Epoch 13, Loss: 0.0795710577145735\n",
      "Epoch 14, Loss: 0.07926310360268134\n",
      "Epoch 15, Loss: 0.07905748500705548\n",
      "Epoch 16, Loss: 0.07882159269018872\n",
      "Epoch 17, Loss: 0.07874055310908191\n",
      "Epoch 18, Loss: 0.07905283575763215\n",
      "Epoch 19, Loss: 0.0790873032066932\n",
      "After interaction 49, reward = 120.0\n",
      "Training the learner\n",
      "Training for 20 epochs\n",
      "Epoch 0, Loss: 0.08224154086348381\n",
      "Epoch 1, Loss: 0.08126674587021426\n",
      "Epoch 2, Loss: 0.0807150769708369\n",
      "Epoch 3, Loss: 0.0805744673271863\n",
      "Epoch 4, Loss: 0.0805221701803328\n",
      "Epoch 5, Loss: 0.08034271667748383\n",
      "Epoch 6, Loss: 0.08022124964788736\n",
      "Epoch 7, Loss: 0.079923030221739\n",
      "Epoch 8, Loss: 0.07958713727306696\n",
      "Epoch 9, Loss: 0.0797346149626249\n",
      "Epoch 10, Loss: 0.07948143173413104\n",
      "Epoch 11, Loss: 0.07913533357699198\n",
      "Epoch 12, Loss: 0.07932949593329548\n",
      "Epoch 13, Loss: 0.07919187472343375\n",
      "Epoch 14, Loss: 0.07883512586346451\n",
      "Epoch 15, Loss: 0.07876660621082156\n",
      "Epoch 16, Loss: 0.07903881913645983\n",
      "Epoch 17, Loss: 0.07852425275875687\n",
      "Epoch 18, Loss: 0.07856699276541458\n",
      "Epoch 19, Loss: 0.0785126391453425\n"
     ]
    }
   ],
   "source": [
    "import dagger\n",
    "\n",
    "dagger.interact(env, learner, agent, observations=observations, actions=actions, checkpoint_path=\"models/DAgger.pth\", seed=seed, num_epochs=40, tqdm_disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118.25\n"
     ]
    }
   ],
   "source": [
    "learner.load_state_dict(torch.load(\"models/DAgger.pth\"), strict=True)\n",
    "total_learner_reward = 0\n",
    "done = False\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for i in range(20):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        with torch.no_grad():\n",
    "            action = learner.get_action(torch.Tensor([obs]).to(device))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_learner_reward += reward\n",
    "\n",
    "print(total_learner_reward/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() missing 6 required positional arguments: 'observations', 'actions', 'rewards', 'next_observations', 'dones', and 'save_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m ACTION_SIZE \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mn\n\u001b[1;32m      7\u001b[0m dqn_learner \u001b[38;5;241m=\u001b[39m DQN(INPUT_SHAPE, ACTION_SIZE)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mdqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdqn_learner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: train() missing 6 required positional arguments: 'observations', 'actions', 'rewards', 'next_observations', 'dones', and 'save_path'"
     ]
    }
   ],
   "source": [
    "from dqn import DQN\n",
    "import dqn\n",
    "\n",
    "INPUT_SHAPE = (210, 160)\n",
    "ACTION_SIZE = env.action_space.n\n",
    "\n",
    "dqn_learner = DQN(INPUT_SHAPE, ACTION_SIZE)\n",
    "\n",
    "dqn.train(dqn_learner, env, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
